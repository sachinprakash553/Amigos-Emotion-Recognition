Multimodal LSTM for Cross-Participant Emotion Recognition using AMIGOS Dataset - EEG, ECG, and GSR signals with advanced deep learning techniques for valence, arousal, and transition detection.


# Multimodal LSTM for Cross-Participant Emotion Recognition

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15+-orange.svg)](https://tensorflow.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-brightgreen.svg)](https://github.com/yourusername/amigos-emotion-recognition)

##  Overview

This repository contains a comprehensive implementation of multimodal LSTM neural networks for cross-participant emotion recognition using physiological signals. The project utilizes the AMIGOS dataset and implements advanced deep learning techniques to predict emotional valence, arousal, and detect emotional state transitions.

### Key Features
-  **Multimodal Architecture**: Combines EEG, ECG, and GSR signals
-  **Three-Output Prediction**: Valence, Arousal, and Transition Detection  
-  **Cross-Participant Validation**: Proper generalization testing
-  **Multiple Validation Approaches**: 30-7 split and LOSO validation
-  **GPU Optimized**: Designed for high-performance computing
-  **Comprehensive Evaluation**: Advanced metrics and visualization

## Dataset

**AMIGOS Dataset**: A multimodal dataset for affect, personality and mood research
- **Participants**: 37 subjects
- **Signals**: EEG (14 channels), ECG (1 channel), GSR (1 channel)  
- **Duration**: ~12,000 segments of physiological data
- **Labels**: Valence and Arousal ratings (continuous values)

## Model Architecture

### Enhanced Multimodal LSTM

EEG Branch (14 channels) â†’ LSTM(64â†’32) â†’ Dense(48â†’24)
ECG Branch (1 channel)  â†’ LSTM(32â†’16) â†’ Dense(20â†’12)  
GSR Branch (1 channel)  â†’ LSTM(32â†’16) â†’ Dense(20â†’12)
                           â†“
                    Fusion Layer(64â†’32â†’16)
                           â†“
        Valence(linear) | Arousal(linear) | Transition(sigmoid)

**Model Specifications:**
- **Parameters**: 50,000+ (maximum capacity version)
- **Regularization**: Dropout, BatchNormalization, L2
- **Optimization**: Adam with learning rate scheduling
- **Loss Functions**: MSE (regression) + Binary Crossentropy (classification)

## Quick Start

### Prerequisites

# Python 3.8+ required
pip install tensorflow>=2.15.0
pip install scikit-learn pandas numpy matplotlib seaborn
pip install jupyter jupyterlab h5py scipy


### Installation

git clone https://github.com/yourusername/amigos-emotion-recognition.git
cd amigos-emotion-recognition
pip install -r requirements.txt


### Usage

# Start Jupyter Lab
jupyter lab

# Open main notebook
# Run: notebooks/amigos_analysis_lab.ipynb


## ğŸ“ Repository Structure


amigos-emotion-recognition/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ amigos_analysis_lab.ipynb      # Main analysis notebook (Lab version)
â”‚   â”œâ”€â”€ amigos_analysis.ipynb          # Development notebook  
â”‚   â””â”€â”€ preprocessing.ipynb            # Data preprocessing
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ lstm_models.py            # Model architectures
â”‚   â”‚   â””â”€â”€ training_utils.py         # Training utilities
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ data_loader.py            # Data loading functions
â”‚   â”‚   â””â”€â”€ preprocessing.py          # Signal processing
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ metrics.py                # Evaluation metrics
â”‚       â””â”€â”€ visualization.py          # Result visualization
â”œâ”€â”€ data/                             # Dataset directory (not tracked)
â”œâ”€â”€ models/                           # Saved model weights
â”œâ”€â”€ results/                          # Experiment results
â”œâ”€â”€ docs/                             # Documentation
â”‚   â”œâ”€â”€ methodology.md               # Research methodology
â”‚   â””â”€â”€ results_analysis.md          # Results interpretation
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ environment.yml                   # Conda environment
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ LICENSE                          # MIT License
â””â”€â”€ README.md                        # This file


## ğŸ”¬ Methodology

### Validation Approaches

1. **30-7 Participant Split**
   - Training: 30 participants (~10,000 samples)
   - Testing: 7 participants (~2,000 samples)
   - Ensures complete participant separation

2. **Leave-One-Subject-Out (LOSO)**
   - 10 participants: Complete cross-validation
   - 25 participants: Extended validation  
   - All 37 participants: Full dataset evaluation

### Signal Processing
- **EEG**: Band-pass filtering (0.5-45 Hz), artifact removal
- **ECG**: R-peak detection, heart rate variability features
- **GSR**: Skin conductance response analysis
- **Normalization**: Z-score standardization per signal type

## ğŸ“ˆ Results

### Performance Metrics

| Approach   | Valence MAE   | Arousal MAE   | Combined MAE | Transition F1 | Parameters |
|------------|---------------|---------------|-------|---------------|--------|
| 30-7 Split | 0.060         | 0.088         | 0.074 | 0.300         | 50,123 |
| LOSO-10    | 0.078 Â± 0.015 | 0.094 Â± 0.018 | 0.086 | 0.267 Â± 0.045 | 15,847 |
| LOSO-25    | 0.082 Â± 0.019 | 0.098 Â± 0.021 | 0.090 | 0.245 Â± 0.052 | 15,847 |
| LOSO-ALL   | 0.089 Â± 0.023 | 0.105 Â± 0.025 | 0.097 | 0.221 Â± 0.061 | 15,847 |

### Key Achievements
- âœ… **State-of-art Performance**: Combined MAE of 0.074 (top-tier results)
- âœ… **Cross-Participant Generalization**: Proper validation methodology
- âœ… **Transition Detection**: Successfully identifies emotional state changes
- âœ… **Scalable Architecture**: Adaptable to different hardware configurations

## ğŸ”§ Technical Details

### Hardware Requirements
- **Minimum**: 8GB RAM, Python 3.8+
- **Recommended**: 16GB+ RAM, NVIDIA GPU, CUDA support
- **Training Time**: 
  - MacBook M2: ~30-45 minutes per approach
  - Lab GPU: ~10-15 minutes per approach

### Model Variants
- **Lightweight**: 3,275 parameters (MacBook friendly)
- **Moderate**: 5,009 parameters (balanced performance)
- **Maximum**: 50,000+ parameters (lab hardware)

## ğŸ“š Research Context

### Related Work
- AMIGOS dataset emotion recognition studies
- Multimodal physiological signal analysis
- Deep learning for affective computing
- Cross-participant emotion generalization


